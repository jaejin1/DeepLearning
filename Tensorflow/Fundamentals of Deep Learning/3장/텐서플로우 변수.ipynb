{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 표준편차를 0.5로 하는 정규분포로 초기화된 텐서를 생성하는 연산자.\n",
    "weights = tf.Variable(tf.random_normal([300,200], stddev=0.5), name=\"weights\")\n",
    "\n",
    "# 가중치가 학습될수 없다면 trainable 옵션을 준다.\n",
    "weights = tf.Variable(tf.random_normal([300,200], stddev=0.5), name=\"weights\"\n",
    "                     ,trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'random_uniform:0' shape=(2, 3) dtype=float32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.random_normal 외에도 텐서플로 변수를 초기화하는 몇 가지 방법이 있다.\n",
    "\n",
    "shape = [2,3]\n",
    "\n",
    "tf.zeros(shape, dtype=tf.float32, name=None)\n",
    "tf.ones(shape, dtype=tf.float32, name=None)\n",
    "tf.random_normal(shape, mean=0.0, stddev=1.0,\n",
    "                dtype=tf.float32, seed=None, name = None)\n",
    "tf.truncated_normal(shape, mean=0.0, stddev=1.0,\n",
    "                   dtype=tf.float32, seed=None, name=None)\n",
    "tf.random_uniform(shape, minval=0, maxval=None,\n",
    "                 dtype=tf.float32, seed=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력을 딥 모델로 전달하는가? 한 개의 변수는 한 번만 초기화되는 것을 의미하기 떄문에 충분하지않다.\n",
    "\n",
    "x = tf.placeholder(tf.float32, name=\"x\", shape=[None, 784])\n",
    "W = tf.Variable(tf.random_uniform([784,10],-1, 1), name=\"W\")\n",
    "multiply = tf.matmul(x,W)\n",
    "\n",
    "# x s는 float32에 저장된 데이터의 미니배치를 나타낸다. 784개 열을 가진다는 것을 알수있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-6b4dbff2729e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-6b4dbff2729e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    from read_data import get_minibatch()\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from read_data import get_minibatch()\n",
    "\n",
    "x = tf.placeholder(tf.float32, name=\"x\", shape=[None, 784])\n",
    "W = tf.Variable(tf.random_uniform([784,10],-1,1), name=\"W\")\n",
    "b = tf.Variable(tf.zeros([10]), name=\"biases\")\n",
    "output = tf.matmul(x, W) + b\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "feed_dict = {\"x\" : get_minibatch()}\n",
    "sess.run(output, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing names of weight parameters\n",
      "W_1_3:0 W_2_1:0 W_3:0\n",
      "Printing names of bias parameters\n",
      "biases_1_2:0 biases_2_1:0 biases_3:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_3:0' shape=(1000, 10) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 신경망 설정은 세 개 층을 설명하는 여섯 개의 변수로 구성된다. \n",
    "# 이 신경망을 여러 번 사용하려고 하면, my_network처럼 여러 번 호출할 수 있는 작은 함수로 캡슐화하는것이 좋다.\n",
    "\n",
    "def my_network(input):\n",
    "    W_1 = tf.Variable(tf.random_uniform([784,100],-1,1), name=\"W_1\")\n",
    "    b_1 = tf.Variable(tf.zeros([100]), name=\"biases_1\")\n",
    "    output_1 = tf.matmul(input, W_1) + b_1\n",
    "    \n",
    "    W_2 = tf.Variable(tf.random_uniform([100,50],-1,1), name=\"W_2\")\n",
    "    b_2 = tf.Variable(tf.zeros([50]), name=\"biases_2\")\n",
    "    output_2 = tf.matmul(output_1, W_2) + b_2\n",
    "    \n",
    "    W_3 = tf.Variable(tf.random_uniform([50,10],-1,1), name=\"W_3\")\n",
    "    b_3 = tf.Variable(tf.zeros([10]), name=\"biases_3\")\n",
    "    output_3 = tf.matmul(output_2, W_3) + b_3\n",
    "    \n",
    "    # 이름 출력\n",
    "    print(\"Printing names of weight parameters\")\n",
    "    print(W_1.name, W_2.name, W_3.name)\n",
    "    print(\"Printing names of bias parameters\")\n",
    "    print(b_1.name, b_2.name, b_3.name)\n",
    "    \n",
    "    return output_3\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([1000,784], stddev=0.5), name=\"weights\")\n",
    "\n",
    "my_network(weights)\n",
    "\n",
    "# 하지만 이렇게 하면 my_network의 두 번째 호출은 첫 번째 호출과 동일한 변수를 사용하지 않는다.\n",
    "# 대신 변수들의 두 번째 집합을 만들었다. 대부분 사본이 아닌 이 모델들을 재사용 하길 원하는데 이 경우 tf.Variable을 사용해서는 안된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **tf.get_varialbe([name], [shape], [initializer])**\n",
    "    \n",
    "    이 이름을 가진 변수가 존재하는지 확인한다. 변수가 존재한다면 검색하고, 변수가 없으면 shape와 initializer로 생성한다.\n",
    "\n",
    "* **tf.variable_scope([scope_name])**\n",
    "    \n",
    "    네임 스페이스를 관리하고 tf.get_variable이 작동하는 범위를 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(input, weight_shape, bias_shape):\n",
    "    weight_init = tf.random_uniform_initializer(minval=-1, maxval=1)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "    b = tf.get_variable(\"b\", vias_shape, initializer=bias_init)\n",
    "    return tf.matmul(input, W) + b\n",
    "\n",
    "def my_network(input):\n",
    "    with tf.variable_scope(\"layer_1\"):\n",
    "        output_1 = layer(input, [784,100], [100])\n",
    "        \n",
    "    with tf.variable_scope(\"layer_2\"):\n",
    "        output_1 = layer(input, [100,50], [50])\n",
    "        \n",
    "    with tf.variable_scope(\"layer_3\"):\n",
    "        output_1 = layer(input, [50,10], [10])\n",
    "        \n",
    "    return output_3\n",
    "\n",
    "# 이케 하면 주어진 이름의 변수가 인스턴스화되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
